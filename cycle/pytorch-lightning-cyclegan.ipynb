{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T11:49:53.858990Z",
     "iopub.status.busy": "2022-07-08T11:49:53.858631Z",
     "iopub.status.idle": "2022-07-08T11:49:53.876238Z",
     "shell.execute_reply": "2022-07-08T11:49:53.874730Z",
     "shell.execute_reply.started": "2022-07-08T11:49:53.858959Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 4109070765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4109070765"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import itertools\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "\n",
    "import wandb\n",
    "\n",
    "pl.seed_everything(hash(\"kek\") % 2**32 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'monet2photo'\n",
    "DATA_PATH = f\"../input/{dataset_name}\"\n",
    "TRAIN_DIR_A = \"trainA\"  # monet\n",
    "TRAIN_DIR_B = \"trainB\"  # photos\n",
    "TEST_DIR_A = \"testA\"  # monet\n",
    "TEST_DIR_B = \"testB\"  # photos\n",
    "\n",
    "PATHS = {\n",
    "    \"train\": {\n",
    "        \"A\": os.path.join(DATA_PATH, TRAIN_DIR_A),\n",
    "        \"B\": os.path.join(DATA_PATH, TRAIN_DIR_B),\n",
    "    },\n",
    "    \"test\": {\n",
    "        \"A\": os.path.join(DATA_PATH, TEST_DIR_A),\n",
    "        \"B\": os.path.join(DATA_PATH, TEST_DIR_B),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T11:27:29.684324Z",
     "iopub.status.busy": "2022-07-08T11:27:29.683647Z",
     "iopub.status.idle": "2022-07-08T11:28:05.592125Z",
     "shell.execute_reply": "2022-07-08T11:28:05.591246Z",
     "shell.execute_reply.started": "2022-07-08T11:27:29.684287Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20220708_112801-odm8kul8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kekus/CycleGAN/runs/odm8kul8\" target=\"_blank\">version2</a></strong> to <a href=\"https://wandb.ai/kekus/CycleGAN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_logger = WandbLogger(project=\"CycleGAN\", name=\"version2\", log_model=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T11:27:25.995254Z",
     "iopub.status.busy": "2022-07-08T11:27:25.994618Z",
     "iopub.status.idle": "2022-07-08T11:27:26.002652Z",
     "shell.execute_reply": "2022-07-08T11:27:26.001261Z",
     "shell.execute_reply.started": "2022-07-08T11:27:25.995216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T11:28:12.159160Z",
     "iopub.status.busy": "2022-07-08T11:28:12.158557Z",
     "iopub.status.idle": "2022-07-08T11:28:12.173389Z",
     "shell.execute_reply": "2022-07-08T11:28:12.172308Z",
     "shell.execute_reply.started": "2022-07-08T11:28:12.159122Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ImageTransform:\n",
    "    def __init__(self, img_size=256):\n",
    "        self.data_transforms = {\n",
    "            \"train\": transforms.Compose(\n",
    "                [\n",
    "                    transforms.Resize(int(img_size * 1.21), Image.Resampling.BICUBIC),\n",
    "                    transforms.RandomCrop(img_size),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "                ]\n",
    "            ),\n",
    "            \"test\": transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "                ]\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def __call__(self, img, phase=\"train\"):\n",
    "        img = self.data_transforms[phase](img)\n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "class MonetDataset(Dataset):\n",
    "    def __init__(self, path_A: str, path_B: str, transform, phase=\"train\"):\n",
    "        self.path_A = glob.glob(os.path.join(path_A, \"*jpg\"))\n",
    "        self.path_B = glob.glob(os.path.join(path_B, \"*jpg\"))\n",
    "        self.transform = transform\n",
    "        self.phase = phase\n",
    "\n",
    "    def __len__(self):\n",
    "        return min([len(self.path_A), len(self.path_B)])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path_A = self.path_A[idx]\n",
    "        path_B = self.path_B[idx]\n",
    "        imgA = Image.open(path_A)\n",
    "        imgB = Image.open(path_B)\n",
    "\n",
    "        imgA = self.transform(imgA, self.phase)\n",
    "        imgB = self.transform(imgB, self.phase)\n",
    "\n",
    "        return imgA, imgB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonetDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = PATHS, batch_size: int = 1):\n",
    "        super().__init__()\n",
    "        self.data_path = data_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            MonetDataset(\n",
    "                self.data_path[\"train\"][\"A\"],\n",
    "                self.data_path[\"train\"][\"B\"],\n",
    "                ImageTransform(),\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            MonetDataset(\n",
    "                self.data_path[\"test\"][\"A\"],\n",
    "                self.data_path[\"test\"][\"B\"],\n",
    "                ImageTransform(),\n",
    "                phase=\"test\",\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePool:\n",
    "    \"\"\"This class implements an image buffer that stores previously generated images.\n",
    "    This buffer enables us to update discriminators using a history of generated images\n",
    "    rather than the ones produced by the latest generators.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pool_size):\n",
    "        \"\"\"Initialize the ImagePool class\n",
    "        Parameters:\n",
    "            pool_size (int) -- the size of image buffer, if pool_size=0, no buffer will be created\n",
    "        \"\"\"\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:  # create an empty pool\n",
    "            self.num_imgs = 0\n",
    "            self.images = []\n",
    "\n",
    "    def query(self, images):\n",
    "        \"\"\"Return an image from the pool.\n",
    "        Parameters:\n",
    "            images: the latest generated images from the generator\n",
    "        Returns images from the buffer.\n",
    "        By 50/100, the buffer will return input images.\n",
    "        By 50/100, the buffer will return images previously stored in the buffer,\n",
    "        and insert the current images to the buffer.\n",
    "        \"\"\"\n",
    "        if self.pool_size == 0:  # if the buffer size is 0, do nothing\n",
    "            return images\n",
    "        return_images = []\n",
    "        for image in images:\n",
    "            image = torch.unsqueeze(image.data, 0)\n",
    "            if (\n",
    "                self.num_imgs < self.pool_size\n",
    "            ):  # if the buffer is not full; keep inserting current images to the buffer\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                self.images.append(image)\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                p = random.uniform(0, 1)\n",
    "                if (\n",
    "                    p > 0.5\n",
    "                ):  # by 50% chance, the buffer will return a previously stored image, and insert the current image into the buffer\n",
    "                    random_id = random.randint(\n",
    "                        0, self.pool_size - 1\n",
    "                    )  # randint is inclusive\n",
    "                    tmp = self.images[random_id].clone()\n",
    "                    self.images[random_id] = image\n",
    "                    return_images.append(tmp)\n",
    "                else:  # by another 50% chance, the buffer will return the current image\n",
    "                    return_images.append(image)\n",
    "        return_images = torch.cat(return_images, 0)  # collect all the images and return\n",
    "        return return_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T11:33:13.691017Z",
     "iopub.status.busy": "2022-07-08T11:33:13.690084Z",
     "iopub.status.idle": "2022-07-08T11:33:13.707176Z",
     "shell.execute_reply": "2022-07-08T11:33:13.704187Z",
     "shell.execute_reply.started": "2022-07-08T11:33:13.690978Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features: int):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_features,\n",
    "                in_features,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                padding_mode=\"reflect\",\n",
    "            ),\n",
    "            nn.InstanceNorm2d(in_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_features,\n",
    "                in_features,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                padding_mode=\"reflect\",\n",
    "            ),\n",
    "            nn.InstanceNorm2d(in_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x) + x\n",
    "\n",
    "\n",
    "class DiscriminatorBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_filters: int,\n",
    "        out_filters: int,\n",
    "        kernel_size: int,\n",
    "        stride: int,\n",
    "        normalize: bool = True,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        layers = [\n",
    "            nn.Conv2d(\n",
    "                in_filters,\n",
    "                out_filters,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=1,\n",
    "            )\n",
    "        ]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_filters))\n",
    "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"x: torch.Tensor\"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T11:33:14.939888Z",
     "iopub.status.busy": "2022-07-08T11:33:14.939534Z",
     "iopub.status.idle": "2022-07-08T11:33:14.960929Z",
     "shell.execute_reply": "2022-07-08T11:33:14.958855Z",
     "shell.execute_reply.started": "2022-07-08T11:33:14.939851Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GeneratorResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Resnet-based generator that consists of Resnet blocks between a few downsampling/upsampling operations.\n",
    "    We adapt Torch code and idea from Justin Johnson's neural style transfer project\n",
    "    (https://github.com/jcjohnson/fast-neural-style)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_channels: int, n_residual_blocks: int = 9):\n",
    "        super().__init__()\n",
    "\n",
    "        def make_generators_layers(\n",
    "            input_channels: int, n_residual_blocks: int\n",
    "        ) -> nn.Sequential:\n",
    "            \"\"\"returns resnet layers for resnet generator\"\"\"\n",
    "            out_features = 64\n",
    "\n",
    "            layers = [\n",
    "                nn.Conv2d(\n",
    "                    input_channels,\n",
    "                    out_features,\n",
    "                    kernel_size=7,\n",
    "                    padding=3,\n",
    "                    padding_mode=\"reflect\",\n",
    "                ),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "\n",
    "            in_features = out_features\n",
    "\n",
    "            for _ in range(2):\n",
    "                out_features *= 2\n",
    "                layers += [\n",
    "                    nn.Conv2d(\n",
    "                        in_features, out_features, kernel_size=3, stride=2, padding=1\n",
    "                    ),\n",
    "                    nn.InstanceNorm2d(out_features),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                ]\n",
    "\n",
    "                in_features = out_features\n",
    "\n",
    "            for _ in range(n_residual_blocks):\n",
    "                layers += [ResidualBlock(out_features)]\n",
    "\n",
    "            for _ in range(2):\n",
    "                out_features //= 2\n",
    "                layers += [\n",
    "                    nn.Upsample(\n",
    "                        scale_factor=2\n",
    "                    ),  # https://distill.pub/2016/deconv-checkerboard/\n",
    "                    nn.Conv2d(\n",
    "                        in_features, out_features, kernel_size=3, stride=1, padding=1\n",
    "                    ),\n",
    "                    nn.InstanceNorm2d(out_features),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                ]\n",
    "\n",
    "                in_features = out_features\n",
    "\n",
    "            layers += [\n",
    "                nn.Conv2d(\n",
    "                    out_features, input_channels, 7, padding=3, padding_mode=\"reflect\"\n",
    "                ),\n",
    "                nn.Tanh(),\n",
    "            ]\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        self.layers = make_generators_layers(input_channels, n_residual_blocks)\n",
    "\n",
    "        self.apply(weights_init_normal)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_channels: int):\n",
    "        super().__init__()\n",
    "\n",
    "        def make_discriminators_layers(input_channels, base_channel_size=64):\n",
    "            \"\"\"makes layers for discriminator\"\"\"\n",
    "            bcs = base_channel_size\n",
    "            layers = [\n",
    "                DiscriminatorBlock(\n",
    "                    input_channels, bcs, kernel_size=4, stride=2, normalize=False\n",
    "                ),\n",
    "                DiscriminatorBlock(bcs, bcs * 2, kernel_size=4, stride=2),\n",
    "                DiscriminatorBlock(bcs * 2, bcs * 4, kernel_size=4, stride=2),\n",
    "                DiscriminatorBlock(bcs * 4, bcs * 8, kernel_size=4, stride=1),\n",
    "                nn.Conv2d(bcs * 8, 1, kernel_size=4, stride=1, padding=1),\n",
    "                # nn.ZeroPad2d((1, 1, 1, 1)),\n",
    "            ]\n",
    "\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        self.layers = make_discriminators_layers(input_channels, base_channel_size=64)\n",
    "\n",
    "        self.apply(weights_init_normal)\n",
    "\n",
    "    def forward(self, image):\n",
    "        return self.layers(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T11:33:16.354529Z",
     "iopub.status.busy": "2022-07-08T11:33:16.354156Z",
     "iopub.status.idle": "2022-07-08T11:33:18.140778Z",
     "shell.execute_reply": "2022-07-08T11:33:18.139773Z",
     "shell.execute_reply.started": "2022-07-08T11:33:16.354500Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen is ok\n",
      "dis is ok\n"
     ]
    }
   ],
   "source": [
    "def test_generator():\n",
    "    g = GeneratorResNet(3)\n",
    "    sample_image = torch.randn(1, 3, 256, 256)\n",
    "    assert g(sample_image).shape == sample_image.shape\n",
    "    print(\"gen is ok\")\n",
    "\n",
    "\n",
    "def test_discriminator():\n",
    "    d = Discriminator((3))\n",
    "    assert d(torch.randn(1, 3, 256, 256)).shape == torch.Size([1, 1, 30, 30])\n",
    "    print(\"dis is ok\")\n",
    "\n",
    "\n",
    "test_generator()\n",
    "test_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_requires_grad(nets, requires_grad):\n",
    "    for net in nets:\n",
    "        for param in net.parameters():\n",
    "            param.requires_grad = requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        G_X,\n",
    "        G_Y,\n",
    "        D_X,\n",
    "        D_Y,\n",
    "        lr=2e-4,\n",
    "        betas=(0.5, 0.999),\n",
    "        cyclic_loss_coef=10,\n",
    "        identity_loss_coef=5,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.G_X = G_X  # style to base X\n",
    "        self.G_Y = G_Y  # base to style Y\n",
    "        self.D_X = D_X  # detect based X\n",
    "        self.D_Y = D_Y  # detect styled Y\n",
    "\n",
    "        self.fakePoolX = ImagePool(50)\n",
    "        self.fakePoolY = ImagePool(50)\n",
    "        self.identity_loss = nn.L1Loss()\n",
    "        self.gan_loss = nn.MSELoss()\n",
    "        self.cycle_loss = nn.L1Loss()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optG = Adam(\n",
    "            itertools.chain(self.G_X.parameters(), self.G_Y.parameters()),\n",
    "            lr=self.hparams.lr,\n",
    "            betas=self.hparams.betas,\n",
    "        )\n",
    "\n",
    "        optD = Adam(\n",
    "            itertools.chain(self.D_X.parameters(), self.D_Y.parameters()),\n",
    "            lr=self.hparams.lr,\n",
    "            betas=self.hparams.betas,\n",
    "        )\n",
    "\n",
    "\n",
    "        gamma = lambda epoch: 1 - max(0, epoch + 1 - 100) / 101\n",
    "\n",
    "        schG = LambdaLR(optG, lr_lambda=gamma)\n",
    "        schD = LambdaLR(optD, lr_lambda=gamma)\n",
    "\n",
    "        return [optG, optD], [schG, schD]\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        x_batch, y_batch = batch  # A and B folders\n",
    "\n",
    "        discriminator_requires_grad = optimizer_idx == 1\n",
    "        set_requires_grad([self.D_X, self.D_Y], discriminator_requires_grad)\n",
    "\n",
    "        x_batch = self.fakePoolX.query(x_batch)\n",
    "        y_batch = self.fakePoolY.query(y_batch)\n",
    "\n",
    "        b = x_batch.size()[0]\n",
    "        true_labels = (torch.randn(b, 1, 30, 30) * 0.3 + 1).type_as(\n",
    "            x_batch\n",
    "        )  # label smoothing Uniform ~ [0.7, 1]\n",
    "        fake_labels = torch.zeros(b, 1, 30, 30).type_as(x_batch)\n",
    "\n",
    "        # Train Generator\n",
    "        if optimizer_idx == 0:\n",
    "\n",
    "            # For painting→photo, we find that it is helpful to introduce an additional\n",
    "            # loss to encourage the mapping to preserve color composition between the input\n",
    "            # and output. In particular, we adopt the technique of Taigman et al.\n",
    "            # https://arxiv.org/pdf/1611.02200.pdf\n",
    "\n",
    "            loss_identity = self.identity_loss(\n",
    "                self.G_X(x_batch), x_batch\n",
    "            ) + self.identity_loss(\n",
    "                self.G_Y(y_batch),\n",
    "                y_batch,\n",
    "            )\n",
    "\n",
    "            x_batch_hat = self.G_X(y_batch)\n",
    "            y_batch_hat = self.G_Y(x_batch)\n",
    "\n",
    "            # Adversarial loss\n",
    "            loss_gan = self.gan_loss(\n",
    "                self.D_X(x_batch_hat), true_labels\n",
    "            ) + self.gan_loss(self.D_Y(y_batch_hat), true_labels)\n",
    "\n",
    "            loss_cycle = self.cycle_loss(self.G_X(y_batch), x_batch) + self.cycle_loss(\n",
    "                self.G_Y(x_batch), y_batch\n",
    "            )\n",
    "\n",
    "            loss_generator = (\n",
    "                loss_gan\n",
    "                + self.hparams.cyclic_loss_coef * loss_cycle\n",
    "                + self.hparams.identity_loss_coef * loss_identity\n",
    "            )\n",
    "\n",
    "            self.log(\"generator/loss\", loss_generator)\n",
    "            self.log(\"generator/adversarial\", loss_gan)\n",
    "            self.log(\"generator/cycle\", loss_cycle)\n",
    "            self.log(\"generator/identity\", loss_identity)\n",
    "\n",
    "            return {\n",
    "                \"loss\": loss_generator,\n",
    "                \"adversarial\": loss_gan,\n",
    "                \"cycle\": loss_cycle,\n",
    "                \"identity\": loss_identity,\n",
    "            }\n",
    "\n",
    "        # Train Discriminator\n",
    "        else:\n",
    "            x_batch_hat = self.G_X(y_batch)\n",
    "            y_batch_hat = self.G_Y(x_batch)\n",
    "\n",
    "            if self.global_step % 499 == 0:\n",
    "                temp = (\n",
    "                    make_grid(\n",
    "                        torch.cat(\n",
    "                            list(\n",
    "                                map(\n",
    "                                    lambda x: x.cpu(),\n",
    "                                    [x_batch, y_batch_hat, y_batch, x_batch_hat],\n",
    "                                )\n",
    "                            )\n",
    "                        ),\n",
    "                        nrow=4,\n",
    "                        padding=0,\n",
    "                    )\n",
    "                    .permute(1, 2, 0)\n",
    "                    .detach()\n",
    "                    .numpy()\n",
    "                )\n",
    "                temp = temp * 0.5 + 0.5\n",
    "                temp = temp * 255.0\n",
    "                temp = temp.astype(int)\n",
    "                wandb.log(\n",
    "                    {\n",
    "                        \"test_images\": wandb.Image(\n",
    "                            temp,\n",
    "                            caption=\"Two on the left: Monet to real image. On the right: vice a versa\",\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            loss_discriminator = (\n",
    "                self.gan_loss(self.D_X(x_batch), true_labels)\n",
    "                + self.gan_loss(self.D_X(x_batch_hat), fake_labels)\n",
    "                + self.gan_loss(self.D_Y(y_batch), true_labels)\n",
    "                + self.gan_loss(self.D_Y(y_batch_hat), fake_labels)\n",
    "            )\n",
    "\n",
    "            self.log(\"discriminator/loss\", loss_discriminator)\n",
    "\n",
    "            return {\"loss\": loss_discriminator}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T11:46:48.109126Z",
     "iopub.status.busy": "2022-07-08T11:46:48.108244Z",
     "iopub.status.idle": "2022-07-08T11:46:48.116422Z",
     "shell.execute_reply": "2022-07-08T11:46:48.115245Z",
     "shell.execute_reply.started": "2022-07-08T11:46:48.109075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(every_n_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T11:46:52.720759Z",
     "iopub.status.busy": "2022-07-08T11:46:52.719705Z",
     "iopub.status.idle": "2022-07-08T11:46:53.318580Z",
     "shell.execute_reply": "2022-07-08T11:46:53.317506Z",
     "shell.execute_reply.started": "2022-07-08T11:46:52.720711Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dm = MonetDataModule()\n",
    "\n",
    "G_base = GeneratorResNet(3)\n",
    "G_style = GeneratorResNet(3)\n",
    "D_base = Discriminator(3)\n",
    "D_style = Discriminator(3)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(every_n_epochs=25)\n",
    "# model_list = [G_base, G_style, D_base, D_style]\n",
    "# path_list = [\"g_base139.pt\", \"g_style139.pt\", \"d_base139.pt\", \"d_style139.pt\"]\n",
    "\n",
    "# LightningModule  --------------------------------------------------------------\n",
    "model = CycleGAN(G_base, G_style, D_base, D_style)\n",
    "\n",
    "# Trainer  --------------------------------------------------------------\n",
    "trainer = Trainer(\n",
    "    logger=wandb_logger,\n",
    "    max_epochs=200,\n",
    "    gpus=0,\n",
    "    reload_dataloaders_every_n_epochs=5,\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=[checkpoint_callback, TQDMProgressBar()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-08T11:50:18.625491Z",
     "iopub.status.busy": "2022-07-08T11:50:18.624761Z",
     "iopub.status.idle": "2022-07-08T15:20:42.052272Z",
     "shell.execute_reply": "2022-07-08T15:20:42.051057Z",
     "shell.execute_reply.started": "2022-07-08T11:50:18.625456Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c23f34d2d349169ac71de86198a261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 300it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('jup')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "1fcb3989e2e6292bebfd54b9b2a9e65f19e9514a81ab82f0dcc28f58557fe757"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
